{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8df6efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from neuralnet import *\n",
    "def how_many_weight_changed(original_nn, new_nn):\n",
    "    changes = []\n",
    "    for n in range(len(original_nn.layers)):\n",
    "        try:\n",
    "            diff = (~np.equal(original_nn.layers[n].w,new_nn.layers[n].w)).sum()\n",
    "            changes.append(diff)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return changes\n",
    "\n",
    "def numerical_approximation_hidden(X, y,episilon = 0.01, n_layer = -1, index = (0,0)):\n",
    "    ''' perform numerical approximation on hidden layer weights'''\n",
    "    \n",
    "    \n",
    "    # start new nn\n",
    "    nn = Neuralnetwork(c)\n",
    "    \n",
    "    # GET w+e\n",
    "    nn.layers[n_layer].w[index]+= episilon\n",
    "    y_hat1 = nn.forward(X)\n",
    "    loss_plus = new_nn.loss(y_hat1, y)\n",
    "    \n",
    "    \n",
    "    # GET w-e\n",
    "    nn.layers[n_layer].w[index]-= 2*episilon\n",
    "    y_hat2 = nn.forward(X)\n",
    "    loss_minus = new_nn.loss(y_hat2, y)\n",
    "    \n",
    "    # restore w\n",
    "    nn.layers[n_layer].w[index]+= episilon\n",
    "    nn(X,y)\n",
    "    nn.backward()\n",
    "    grad = nn.layers[n_layer].d_w[index]\n",
    "    \n",
    "    \n",
    "    return grad, (loss_plus-loss_minus)/(2*episilon)\n",
    "\n",
    "def numerical_approximation_bias(X, y,episilon = 0.01, n_layer = -1, index = (0)):\n",
    "    ''' perform numerical approximation on hidden layer bias'''\n",
    "    \n",
    "    # calculate w+E\n",
    "    \n",
    "    # start new nn\n",
    "    nn = Neuralnetwork(c)\n",
    "    \n",
    "    # GET w+e\n",
    "    nn.layers[n_layer].b[0,index]+= episilon\n",
    "    y_hat1 = nn.forward(X)\n",
    "    loss_plus = new_nn.loss(y_hat1, y)\n",
    "    \n",
    "    \n",
    "    # GET w-e\n",
    "    nn.layers[n_layer].b[0,index]-= 2*episilon\n",
    "    y_hat2 = nn.forward(X)\n",
    "    loss_minus = new_nn.loss(y_hat2, y)\n",
    "    \n",
    "    # restore w\n",
    "    nn.layers[n_layer].b[0,index]+= episilon\n",
    "    nn(X,y)\n",
    "    nn.backward()\n",
    "    grad = nn.layers[n_layer].d_b[index]\n",
    "    \n",
    "    return grad, (loss_plus-loss_minus)/(2*episilon)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7577e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====USING 10 training example, episilon = 0.0001====\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.3906991204798476 1.3906920287246993\n",
      "--- weight at layer -1, index 5,1---\n",
      "nngrad=0.04545877574050213, approx=0.035458775741181725\n",
      "diff=0.009999999999320407\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.3906956201873082 1.3906955289928447\n",
      "--- weight at layer -1, index 5,2---\n",
      "nngrad=0.0004559723168346502, approx=0.00045597231768113033\n",
      "diff=-8.4648011256655e-13\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.390695983423489 1.3906951657779851\n",
      "--- weight at layer -1, index 5,3---\n",
      "nngrad=0.004088227518042479, approx=0.004088227519849497\n",
      "diff=-1.8070172094764025e-12\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.3906951353082146 1.3906960138736792\n",
      "--- weight at layer -1, index 5,4---\n",
      "nngrad=-0.004392827322034191, approx=-0.004392827323007609\n",
      "diff=9.734175271391976e-13\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.390695719414785 1.3906954297667897\n",
      "--- weight at layer -1, index 5,5---\n",
      "nngrad=0.0014482399752158925, approx=0.0014482399768311893\n",
      "diff=-1.6152968719540528e-12\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.390695579715987 1.390695569457743\n",
      "--- weight at layer -1, index 5,6---\n",
      "nngrad=5.129121893530899e-05, approx=5.12912201600102e-05\n",
      "diff=-1.2247012079599426e-12\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.3906945875342944 1.3906965616402753\n",
      "--- weight at layer -1, index 5,7---\n",
      "nngrad=-0.009870529904402323, approx=-0.009870529904532077\n",
      "diff=1.2975384655611322e-13\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.390695575197682 1.390695573975709\n",
      "--- weight at layer -1, index 5,8---\n",
      "nngrad=6.109863745905832e-06, approx=6.109864836290058e-06\n",
      "diff=-1.090384225510381e-12\n",
      "\n",
      "\n",
      "divided!!\n",
      "divided!!\n",
      "divided!!\n",
      "[0, 0, 1]\n",
      "[0, 0, 1]\n",
      "1.390695574424306 1.3906955747490695\n",
      "--- weight at layer -1, index 5,9---\n",
      "nngrad=-1.6238179743385286e-06, approx=-1.623817746931877e-06\n",
      "diff=-2.2740665149465985e-13\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataloader import *\n",
    "c = load_config('config.yaml')\n",
    "d = DataLoader() # data loader does everything for u\n",
    "X = d.X_train[5000:5010, :]\n",
    "y = d.y_train[5000:5010]\n",
    "\n",
    "print('====USING 10 training example, episilon = 0.0001====')\n",
    "for i in range(1,10):\n",
    "    nngrad, approx = numerical_approximation_hidden(X, y, n_layer = -1, episilon = 0.0001, index = (3,i))\n",
    "    print(f'--- weight at layer -1, index 5,{i}---')\n",
    "    print(f'nngrad={nngrad}, approx={approx}')\n",
    "    print(f'diff={nngrad-approx}')\n",
    "    \n",
    "    print('\\n')\n",
    "                                                    \n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69de4234",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/scratch/hsher/28059077.tscc-mgr7.local/ipykernel_58002/3086819404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnngrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapprox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumerical_approximation_bias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'--- bias at layer -1, index 5,{i}---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'nngrad={nngrad}, approx={approx}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/hsher/28059077.tscc-mgr7.local/ipykernel_58002/3836890072.py\u001b[0m in \u001b[0;36mnumerical_approximation_bias\u001b[0;34m(X, y, episilon, n_layer, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mepisilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0my_hat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mloss_plus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_nn' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    \n",
    "    nngrad, approx = numerical_approximation_bias(X, y, n_layer = -1, episilon = 0.01, index = i)\n",
    "    print(f'--- bias at layer -1, index 5,{i}---')\n",
    "    print(f'nngrad={nngrad}, approx={approx}')\n",
    "    print(f'diff={nngrad-approx}')\n",
    "    \n",
    "    print('\\n')\n",
    "                      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c8c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
